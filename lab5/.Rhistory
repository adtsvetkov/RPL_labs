"10-08-2019",
"07-08-2020"), "%d-%m-%Y")
nal
hist(perevod)
hist(perevod, "days")
hist(perevod, "months")
nal <- format(nal, "%d%m")
nal
nal <- as.Date(c("22-07-2017",
"19-08-2017",
"10-12-2017",
"22-01-2018",
"29-04-2018",
"26-08-2018",
"12-12-2018",
"04-01-2019",
"28-05-2019",
"10-08-2019",
"07-08-2020"), "%d-%m-%Y")
nal <- format(nal, "%d.%m")
nal
hist(nal, "days")
nal <- format(as.Date(nal), "%d.%m")
perevodday <- c(29, 25, 14, 23, 17, 6, 8, 30, 26, 3, 26, 17, 14, 10, 21, 4)
nalday <- c(22, 19, 10, 22, 29, 26, 12, 4, 28, 10, 7)
hist(perevodday)
hist(nalday)
hist(perevodday + nalday)
hist(c(perevodday + nalday))
hist(c(perevodday, nalday))
hist(c(perevodday))
install.packages("DescTools")
library(DescTools)
A <- c(466,481,744,709,1922,57,329,42,314,257,274,83,44,813,217,538,17,83,458,52,71,216,424,30,249,571,163,192,179,1819,77,121,679,135,67,467,93,119,152,722,612,308,39,110,445,235,78,292,303,571,745,238,517,116,22,183,149,629,881,857,103,443,143,251,3851,391,571,78,68,110,327,167,83,39,108,161,359,424,95,67,288,3163,83,344,629,733,124,119,481,554,17,599,405,371,30,454,245,539,119,142,554,159,454,219,62,452,467,560,250,75,42,107,428,554,263,359,54,71,53,90,803,143,1166,18,415,83,305,730,439,122,3348,427,109,319,182,593,552,465,83,368,571,353,379,74,83,268,2464,83,158,530,527,159,191,253,419,52,80,314,283,981,1122,17,106,938,369,419,583,949,52,263,502,524,108,128,749,198,359,501,17,140,554,3032,1129,224,483,571,68,96,290,55,83,59,345,119,808,329,233,143,144,141,176,170,799,19,174,39,808,795,71,558,315,453,163,37,52,94,180,71,173,242,125,186,62,506,250,141,389,591,89,100,467,35,114,187,439,83,233,36,358,439,158,52,291,42,23,148,19,72,272,1250,136,145,406,315,149,57,656,23,398,599,504,337,219,333,448,651,83,67,28,215,134,167,4587,68,52,527,233,374,43,38,308,349,776,44,324,454,653,656,51,39,183,463,723,99,288,17,39,333,300,410,29,99,438,83,83,106,818,102,67,192,97,786,571,503,349,171,866,484,67,108,133,571,110,116,404,171,67,231,100,571,271,359,3416,510,588,454,211,571,285,305,17,183,53,156,810,90,117,218,159,27,39,172,373,302,467,185,162,226,52,78,2099,23,844,430,163,701,59,115,61,472,243,245,752,42,571,620,141,18,33,27,47,114,171,439,504,35,793,570,117,136,631,75,660,19,536,439,308,1848,219,78,405,331,500,285,108,585,274,112,539,454,717,659,677,29,47,415,119,339,107,198,42,150,316,607,301,136,52,1267,79,592,483,144,538,17,203,709,158,83,414,42,561,309,79,237,450,140,163,52,17,378,39,205,102,375,63,37,82,172,82,252,199,508,17,449,219,291,141,119,881,77,67,13,180,286,5008,1696,571,359,717,349,454,302,454,635,255,599,804,239,52,329,63,142,107,454,100,484,39,130,147,81,826,185,3158,239,219,42,345,68,113,506,755,448,358,881,17,876,215,308,33,241,439,358,42,191,146,17,153,439,174,439,1428,833,212,50,110,389,191,61,274,91,77,97,344,612,46,395,41,677,71,415,74,52,1116,83,78,29,52,1064,81,64,387,135,66,234,71,271,219,52,79,1420,228,35,6071,149,120,191,333,233,153,119,201,67,583,349,483,17,778,243,67,164,58,204,273,236,876,208,17,143,58,158,969,238,119,1018,629,17,176,774,183,343,245,75,461,39,66,645,208,207,83,319,409,52,808,833,417,507,439,122,143,329,348,203,184,113,1414,200,927,503,329,349,74,45,389,260,439,669,272,187,377,499,57,4675,139,746,77,17,367,125,41,451,137,227,266,18,516,522,557,163,350,439,439,112,329,136,163,57,19,40,179,284,193,108,219,19,389,137,58,56,422,274,135,571,534,136,709,183,83,44,337,117,27,153,68,167,132,96,775,234,123,55,99,52,102,188,527,389,70,52,1340,454,186,55,388,149,227,263,66,29,133,624,6187,153,108,263,119,219,94,191,83,127,52,54,52,582,242,152,201,359,308,8658,75,67,349,422,89,52,59,577,188,68,59,136,4,298,268,179,52,46,493,645,67,439,68,103,459,371,361,562,283,206,92,373,266,57,42,79,74,112,266,107,104,128,19,349,349,2475,550,14,78,57,273,48,483,313,709,43,390,460,18,463,114,571,353,19,19,276,265,102,255,324,113,14,43,2252,571,490,1404,527,454,1428,99,39,140,5237,52,128,561,68,391,389,133,1343,320,329,213,253,167,249,249,496,220,173,439,337,274,492,571,28,149,145,68,1130,405,47,360,1126,9454,110,253,289,289,349,404,240,107,573,18,776,219,158,512,728,122,492,59,1995,109,452,60,404,329,237,799,190,396,1358,75,33,674,281,39,43,42,174,188,439,313,83,301,18,67,244,634,68,233,52,57,136,433,103,258,227,818,83,68,78,19,35,63,413,224,1043,71,301,31,464,292,191,50,379,1096,213,660,143,172,466,369,263,17,101,6266,50,102,449,128,236,220,79,379,387,163,421,52,506,67,435,439,583,17,559,321,325,1567,527,133,440,420,1288,144,314,285,764,231,379,14,66,349,163,465,39,448,701,248,199,77,7339,1
8,182,578,39)
MedianCI(A)
A
A <- c(466,481,744,709,1922,57,329,42,314,257,274,83,44,813,217,538,17,83,458,52,71,216,424,30,249,571,163,192,179,1819,77,121,679,135,67,467,93,119,152,722,612,308,39,110,445,235,78,292,303,571,745,238,517,116,22,183,149,629,881,857,103,443,143,251,3851,391,571,78,68,110,327,167,83,39,108,161,359,424,95,67,288,3163,83,344,629,733,124,119,481,554,17,599,405,371,30,454,245,539,119,142,554,159,454,219,62,452,467,560,250,75,42,107,428,554,263,359,54,71,53,90,803,143,1166,18,415,83,305,730,439,122,3348,427,109,319,182,593,552,465,83,368,571,353,379,74,83,268,2464,83,158,530,527,159,191,253,419,52,80,314,283,981,1122,17,106,938,369,419,583,949,52,263,502,524,108,128,749,198,359,501,17,140,554,3032,1129,224,483,571,68,96,290,55,83,59,345,119,808,329,233,143,144,141,176,170,799,19,174,39,808,795,71,558,315,453,163,37,52,94,180,71,173,242,125,186,62,506,250,141,389,591,89,100,467,35,114,187,439,83,233,36,358,439,158,52,291,42,23,148,19,72,272,1250,136,145,406,315,149,57,656,23,398,599,504,337,219,333,448,651,83,67,28,215,134,167,4587,68,52,527,233,374,43,38,308,349,776,44,324,454,653,656,51,39,183,463,723,99,288,17,39,333,300,410,29,99,438,83,83,106,818,102,67,192,97,786,571,503,349,171,866,484,67,108,133,571,110,116,404,171,67,231,100,571,271,359,3416,510,588,454,211,571,285,305,17,183,53,156,810,90,117,218,159,27,39,172,373,302,467,185,162,226,52,78,2099,23,844,430,163,701,59,115,61,472,243,245,752,42,571,620,141,18,33,27,47,114,171,439,504,35,793,570,117,136,631,75,660,19,536,439,308,1848,219,78,405,331,500,285,108,585,274,112,539,454,717,659,677,29,47,415,119,339,107,198,42,150,316,607,301,136,52,1267,79,592,483,144,538,17,203,709,158,83,414,42,561,309,79,237,450,140,163,52,17,378,39,205,102,375,63,37,82,172,82,252,199,508,17,449,219,291,141,119,881,77,67,13,180,286,5008,1696,571,359,717,349,454,302,454,635,255,599,804,239,52,329,63,142,107,454,100,484,39,130,147,81,826,185,3158,239,219,42,345,68,113,506,755,448,358,881,17,876,215,308,33,241,439,358,42,191,146,17,153,439,174,439,1428,833,212,50,110,389,191,61,274,91,77,97,344,612,46,395,41,677,71,415,74,52,1116,83,78,29,52,1064,81,64,387,135,66,234,71,271,219,52,79,1420,228,35,6071,149,120,191,333,233,153,119,201,67,583,349,483,17,778,243,67,164,58,204,273,236,876,208,17,143,58,158,969,238,119,1018,629,17,176,774,183,343,245,75,461,39,66,645,208,207,83,319,409,52,808,833,417,507,439,122,143,329,348,203,184,113,1414,200,927,503,329,349,74,45,389,260,439,669,272,187,377,499,57,4675,139,746,77,17,367,125,41,451,137,227,266,18,516,522,557,163,350,439,439,112,329,136,163,57,19,40,179,284,193,108,219,19,389,137,58,56,422,274,135,571,534,136,709,183,83,44,337,117,27,153,68,167,132,96,775,234,123,55,99,52,102,188,527,389,70,52,1340,454,186,55,388,149,227,263,66,29,133,624,6187,153,108,263,119,219,94,191,83,127,52,54,52,582,242,152,201,359,308,8658,75,67,349,422,89,52,59,577,188,68,59,136,4,298,268,179,52,46,493,645,67,439,68,103,459,371,361,562,283,206,92,373,266,57,42,79,74,112,266,107,104,128,19,349,349,2475,550,14,78,57,273,48,483,313,709,43,390,460,18,463,114,571,353,19,19,276,265,102,255,324,113,14,43,2252,571,490,1404,527,454,1428,99,39,140,5237,52,128,561,68,391,389,133,1343,320,329,213,253,167,249,249,496,220,173,439,337,274,492,571,28,149,145,68,1130,405,47,360,1126,9454,110,253,289,289,349,404,240,107,573,18,776,219,158,512,728,122,492,59,1995,109,452,60,404,329,237,799,190,396,1358,75,33,674,281,39,43,42,174,188,439,313,83,301,18,67,244,634,68,233,52,57,136,433,103,258,227,818,83,68,78,19,35,63,413,224,1043,71,301,31,464,292,191,50,379,1096,213,660,143,172,466,369,263,17,101,6266,50,102,449,128,236,220,79,379,387,163,421,52,506,67,435,439,583,17,559,321,325,1567,527,133,440,420,1288,144,314,285,764,231,379,14,66,349,163,465,39,448,701,248,199,77,7339,1
8,182,578,39)
A <- c(466,481,744,709,1922,57,329,42,314,257,274,83,44,813,217,538,17,83,458,52,71,216,424,30,249,571,163,192,179,1819,77,121,679,135,67,467,93,119,152,722,612,308,39,110,445,235,78,292,303,571,745,238,517,116,22,183,149,629,881,857,103,443,143,251,3851,391,571,78,68,110,327,167,83,39,108,161,359,424,95,67,288,3163,83,344,629,733,124,119,481,554,17,599,405,371,30,454,245,539,119,142,554,159,454,219,62,452,467,560,250,75,42,107,428,554,263,359,54,71,53,90,803,143,1166,18,415,83,305,730,439,122,3348,427,109,319,182,593,552,465,83,368,571,353,379,74,83,268,2464,83,158,530,527,159,191,253,419,52,80,314,283,981,1122,17,106,938,369,419,583,949,52,263,502,524,108,128,749,198,359,501,17,140,554,3032,1129,224,483,571,68,96,290,55,83,59,345,119,808,329,233,143,144,141,176,170,799,19,174,39,808,795,71,558,315,453,163,37,52,94,180,71,173,242,125,186,62,506,250,141,389,591,89,100,467,35,114,187,439,83,233,36,358,439,158,52,291,42,23,148,19,72,272,1250,136,145,406,315,149,57,656,23,398,599,504,337,219,333,448,651,83,67,28,215,134,167,4587,68,52,527,233,374,43,38,308,349,776,44,324,454,653,656,51,39,183,463,723,99,288,17,39,333,300,410,29,99,438,83,83,106,818,102,67,192,97,786,571,503,349,171,866,484,67,108,133,571,110,116,404,171,67,231,100,571,271,359,3416,510,588,454,211,571,285,305,17,183,53,156,810,90,117,218,159,27,39,172,373,302,467,185,162,226,52,78,2099,23,844,430,163,701,59,115,61,472,243,245,752,42,571,620,141,18,33,27,47,114,171,439,504,35,793,570,117,136,631,75,660,19,536,439,308,1848,219,78,405,331,500,285,108,585,274,112,539,454,717,659,677,29,47,415,119,339,107,198,42,150,316,607,301,136,52,1267,79,592,483,144,538,17,203,709,158,83,414,42,561,309,79,237,450,140,163,52,17,378,39,205,102,375,63,37,82,172,82,252,199,508,17,449,219,291,141,119,881,77,67,13,180,286,5008,1696,571,359,717,349,454,302,454,635,255,599,804,239,52,329,63,142,107,454,100,484,39,130,147,81,826,185,3158,239,219,42,345,68,113,506,755,448,358,881,17,876,215,308,33,241,439,358,42,191,146,17,153,439,174,439,1428,833,212,50,110,389,191,61,274,91,77,97,344,612,46,395,41,677,71,415,74,52,1116,83,78,29,52,1064,81,64,387,135,66,234,71,271,219,52,79,1420,228,35,6071,149,120,191,333,233,153,119,201,67,583,349,483,17,778,243,67,164,58,204,273,236,876,208,17,143,58,158,969,238,119,1018,629,17,176,774,183,343,245,75,461,39,66,645,208,207,83,319,409,52,808,833,417,507,439,122,143,329,348,203,184,113,1414,200,927,503,329,349,74,45,389,260,439,669,272,187,377,499,57,4675,139,746,77,17,367,125,41,451,137,227,266,18,516,522,557,163,350,439,439,112,329,136,163,57,19,40,179,284,193,108,219,19,389,137,58,56,422,274,135,571,534,136,709,183,83,44,337,117,27,153,68,167,132,96,775,234,123,55,99,52,102,188,527,389,70,52,1340,454,186,55,388,149,227,263,66,29,133,624,6187,153,108,263,119,219,94,191,83,127,52,54,52,582,242,152,201,359,308,8658,75,67,349,422,89,52,59,577,188,68,59,136,4,298,268,179,52,46,493,645,67,439,68,103,459,371,361,562,283,206,92,373,266,57,42,79,74,112,266,107,104,128,19,349,349,2475,550,14,78,57,273,48,483,313,709,43,390,460,18,463,114,571,353,19,19,276,265,102,255,324,113,14,43,2252,571,490,1404,527,454,1428,99,39,140,5237,52,128,561,68,391,389,133,1343,320,329,213,253,167,249,249,496,220,173,439,337,274,492,571,28,149,145,68,1130,405,47,360,1126,9454,110,253,289,289,349,404,240,107,573,18,776,219,158,512,728,122,492,59,1995,109,452,60,404,329,237,799,190,396,1358,75,33,674,281,39,43,42,174,188,439,313,83,301,18,67,244,634,68,233,52,57,136,433,103,258,227,818,83,68,78,19,35,63,413,224,1043,71,301,31,464,292,191,50,379,1096,213,660,143,172,466,369,263,17,101,6266,50,102,449,128,236,220,79,379,387,163,421,52,506,67,435,439,583,17,559,321,325,1567,527,133,440,420,1288,144,314,285,764,231,379,14,66,349,163,465,39,448,701,248,199,77,7339,18,182,578,39)
MedianCI(A)
vec <- c(6718.93,	6704.53,	6721.29,	6716.21,	6699.15,	6688.96,	6678.15,	6704.53,	6731.17,	6798.8,	6759.51,	6808.85,	6751.87,	6694.95,	6617.28,	6645.87,	6620.61,	6504.57,	6570.76,	6542.43,	6561.85, 6503.34,	6549.24,	6549.24,	6546.42,	6558.46,	6583.42,	6614.21,	6576.96,	6571.84,	6573.22,	6639.11,	6663.19,	6664.72,	6663.8,	6625.68,	6631.93,	6650.69,	6652.84,	6638.49,	6600.73,	6620.56,	6668.46,	6720.31,	6742.14,	6756.23,	6716.27,	6678.15,	6676.92,	6685.01,	6706.89,	6667.85,	6702.79,	6692.8,	6727.18,	6720.93,	6669.69,	6659.09,	6645.67,	6684.4,	6775.85,	6750.29,	6827.39,	6863.31,	6892.66,	6899.84,	6859.87,	6831.75,	6831.75,	6835.9,	6809.46,	6826.67,	6748.85,	6702.02,	6720.52,	6738.96,	6801.77,	6756.18,	6744.39,	6619.74, 6585.62,	6580.85,	6565.53,	6581.16,	6597.4,	6623.28,	6580.19,	6587.57,	6579.21,	6489.61,	6451.49,	6432.63,	6464.96,	6519.07,	6603.55,	6609.96,	6629.78,	6664.06,	6672.67,	6669.49,	6720.36,	6672.36,	6637.16)
library(forecast)
auto.arima(vec)
vec <- c(6718.93,	6704.53,	6721.29,	6716.21,	6699.15,	6688.96,	6678.15,	6704.53,	6731.17,	6798.8,	6759.51,	6808.85,	6751.87,	6694.95,	6617.28,	6645.87,	6620.61,	6504.57,	6570.76,	6542.43,	6561.85, 6503.34,	6549.24,	6549.24,	6546.42,	6558.46,	6583.42,	6614.21,	6576.96,	6571.84,	6573.22,	6639.11,	6663.19,	6664.72,	6663.8,	6625.68,	6631.93,	6650.69,	6652.84,	6638.49,	6600.73,	6620.56,	6668.46,	6720.31,	6742.14,	6756.23,	6716.27,	6678.15,	6676.92,	6685.01,	6706.89,	6667.85,	6702.79,	6692.8,	6727.18,	6720.93,	6669.69,	6659.09,	6645.67,	6684.4,	6775.85,	6750.29,	6827.39,	6863.31,	6892.66,	6899.84,	6859.87,	6831.75,	6831.75,	6835.9,	6809.46,	6826.67,	6748.85,	6702.02,	6720.52,	6738.96,	6801.77,	6756.18,	6744.39,	6619.74, 6585.62,	6580.85,	6565.53,	6581.16,	6597.4,	6623.28,	6580.19,	6587.57,	6579.21,	6489.61,	6451.49,	6432.63,	6464.96,	6519.07,	6603.55,	6609.96,	6629.78,	6664.06,	6672.67,	6669.49,	6720.36,	6672.36,	6637.16)
library(tseries)
adf.test(vec)
kpss.test(vec)
vec <- c(6718.93,	6704.53,	6721.29,	6716.21,	6699.15,	6688.96,	6678.15,	6704.53,	6731.17,	6798.8,	6759.51,	6808.85,	6751.87,	6694.95,	6617.28,	6645.87,	6620.61,	6504.57,	6570.76,	6542.43,	6561.85, 6503.34,	6549.24,	6549.24,	6546.42,	6558.46,	6583.42,	6614.21,	6576.96,	6571.84,	6573.22,	6639.11,	6663.19,	6664.72,	6663.8,	6625.68,	6631.93,	6650.69,	6652.84,	6638.49,	6600.73,	6620.56,	6668.46,	6720.31,	6742.14,	6756.23,	6716.27,	6678.15,	6676.92,	6685.01,	6706.89,	6667.85,	6702.79,	6692.8,	6727.18,	6720.93,	6669.69,	6659.09,	6645.67,	6684.4,	6775.85,	6750.29,	6827.39,	6863.31,	6892.66,	6899.84,	6859.87,	6831.75,	6831.75,	6835.9,	6809.46,	6826.67,	6748.85,	6702.02,	6720.52,	6738.96,	6801.77,	6756.18,	6744.39,	6619.74, 6585.62,	6580.85,	6565.53,	6581.16,	6597.4,	6623.28,	6580.19,	6587.57,	6579.21,	6489.61,	6451.49,	6432.63,	6464.96,	6519.07,	6603.55,	6609.96,	6629.78,	6664.06,	6672.67,	6669.49,	6720.36,	6672.36,	6637.16)
library(tseries)
adf.test(vec)
kpss.test(vec)
differentiation <- function(Y, n)
{
Y1 <- Y
first_elems <- vector()
for (i in 1:n)
{
Y2 <- vector()
first_elems <- append(first_elems, Y1[1])
for (j in 1:(length(Y1) - 1)) Y2 <- append(Y2, Y1[j+1] - Y1[j])
Y1 <- Y2
}
return(list(diff = Y2, recover = rev(first_elems)))
}
vec2 <- differentiation(vec, 1)
adf.test(vec2)
adf.test(vec2$diff)
vec <- c(6718.93,	6704.53,	6721.29,	6716.21,	6699.15,	6688.96,	6678.15,	6704.53,	6731.17,	6798.8,	6759.51,	6808.85,	6751.87,	6694.95,	6617.28,	6645.87,	6620.61,	6504.57,	6570.76,	6542.43,	6561.85, 6503.34,	6549.24,	6549.24,	6546.42,	6558.46,	6583.42,	6614.21,	6576.96,	6571.84,	6573.22,	6639.11,	6663.19,	6664.72,	6663.8,	6625.68,	6631.93,	6650.69,	6652.84,	6638.49,	6600.73,	6620.56,	6668.46,	6720.31,	6742.14,	6756.23,	6716.27,	6678.15,	6676.92,	6685.01,	6706.89,	6667.85,	6702.79,	6692.8,	6727.18,	6720.93,	6669.69,	6659.09,	6645.67,	6684.4,	6775.85,	6750.29,	6827.39,	6863.31,	6892.66,	6899.84,	6859.87,	6831.75,	6831.75,	6835.9,	6809.46,	6826.67,	6748.85,	6702.02,	6720.52,	6738.96,	6801.77,	6756.18,	6744.39,	6619.74, 6585.62,	6580.85,	6565.53,	6581.16,	6597.4,	6623.28,	6580.19,	6587.57,	6579.21,	6489.61,	6451.49,	6432.63,	6464.96,	6519.07,	6603.55,	6609.96,	6629.78,	6664.06,	6672.67,	6669.49,	6720.36,	6672.36,	6637.16)
library(tseries)
#adf.test(vec)
#kpss.test(vec)
differentiation <- function(Y, n)
{
Y1 <- Y
first_elems <- vector()
for (i in 1:n)
{
Y2 <- vector()
first_elems <- append(first_elems, Y1[1])
for (j in 1:(length(Y1) - 1)) Y2 <- append(Y2, Y1[j+1] - Y1[j])
Y1 <- Y2
}
return(list(diff = Y2, recover = rev(first_elems)))
}
#vec2 <- differentiation(vec, 1)
#adf.test(vec2$diff)
auto.arima(vec)
arima(vec, order=(1, 0, 0))
arima(new_vec, order=c(1, 0, 0))
arima(vec2, order=c(1, 0, 0))
vec <- c(6718.93,	6704.53,	6721.29,	6716.21,	6699.15,	6688.96,	6678.15,	6704.53,	6731.17,	6798.8,	6759.51,	6808.85,	6751.87,	6694.95,	6617.28,	6645.87,	6620.61,	6504.57,	6570.76,	6542.43,	6561.85, 6503.34,	6549.24,	6549.24,	6546.42,	6558.46,	6583.42,	6614.21,	6576.96,	6571.84,	6573.22,	6639.11,	6663.19,	6664.72,	6663.8,	6625.68,	6631.93,	6650.69,	6652.84,	6638.49,	6600.73,	6620.56,	6668.46,	6720.31,	6742.14,	6756.23,	6716.27,	6678.15,	6676.92,	6685.01,	6706.89,	6667.85,	6702.79,	6692.8,	6727.18,	6720.93,	6669.69,	6659.09,	6645.67,	6684.4,	6775.85,	6750.29,	6827.39,	6863.31,	6892.66,	6899.84,	6859.87,	6831.75,	6831.75,	6835.9,	6809.46,	6826.67,	6748.85,	6702.02,	6720.52,	6738.96,	6801.77,	6756.18,	6744.39,	6619.74, 6585.62,	6580.85,	6565.53,	6581.16,	6597.4,	6623.28,	6580.19,	6587.57,	6579.21,	6489.61,	6451.49,	6432.63,	6464.96,	6519.07,	6603.55,	6609.96,	6629.78,	6664.06,	6672.67,	6669.49,	6720.36,	6672.36,	6637.16)
library(tseries)
library(forecast)
#adf.test(vec)
#kpss.test(vec)
differentiation <- function(Y, n)
{
Y1 <- Y
first_elems <- vector()
for (i in 1:n)
{
Y2 <- vector()
first_elems <- append(first_elems, Y1[1])
for (j in 1:(length(Y1) - 1)) Y2 <- append(Y2, Y1[j+1] - Y1[j])
Y1 <- Y2
}
return(list(diff = Y2, recover = rev(first_elems)))
}
vec2 <- differentiation(vec, 1)
adf.test(vec2$diff)
auto.arima(vec)
arima(vec2, order=c(1, 0, 0))
arima(vec2$diff, order=c(1, 0, 0))
arima(vec2$diff, order=c(1, 0, 0), include.mean = F)
ar <- arima(vec2$diff, order=c(1, 0, 0), include.mean = F)
ar$sigma2
ar <- arima(vec2$diff, order=c(1, 0, 0))
ar$sigma2
ar <- arima(vec2$diff, order=c(1, 0, 0))
ar <- arima(vec2$diff, order=c(1, 0, 0), include.mean = F)
ar <- arma(vec2$diff, oder(1, 0), include.intercept = F)
ar <- arma(vec2$diff, order=c(1, 0), include.intercept = F)
ar$coef
ar$fitted.values
length(vec)
length(vec2)
length(vec2$diff)
vec2$diff
ar$css
ar$residuals
arma(vec2$diff, order=c(1, 0), include.intercept = F)
ar <- arima(vec2$diff, order=c(1, 0, 0), include.mean = F)
ar
a <- data.frame()
a
rbind(a, c(1, 1))
rbind(a, kek = 1, kek1 =2)
rbind(a, c(1, 1))
rbind(a, c(1, 2))
ar$residuals
ar <- arma(vec2$diff, order=c(1, 0), include.intercept = F)
ar$residuals
na.omit(ar$residuals)
n <- na.omit(ar$residuals)
n
len(n)
length(n)
ar <- arma(vec2$diff, order=c(1, 0), include.intercept = F)
ar$coef
length(ar$coeff)
length(ar$coef)
ar <- arma(vec2$diff, order=c(1, 0), include.intercept = F)
ar$residuals
auto.arima(vec)
arimaa <- auto.arima(vec)
arimaa$coef
arimaa$sigma2
auto.arima(vec2)
auto.arima(vec2$diff)
auto.arima(vec2$diff)$coef
arimaa$coef
arimaa$residuals
arimaa$sigma2
```R
library(tseries)
library(forecast)
library(knitr)
```
### Исследование ряда
<div style="text-align: right"> Выполнил студент гр. 3740904/10301 Цветков Алексей</div>
# Построение модели ARIMA
## Ряд №2843
#### Данный документ создан в качестве эксперимента в сравнение с данными, полученными с помощью метода ОПГ (Excel)
Зададим исследуемый ряд:
```R
vec <- c(6718.93, 6704.53, 6721.29, 6716.21, 6699.15, 6688.96, 6678.15, 6704.53, 6731.17, 6798.8, 6759.51,
6808.85, 6751.87, 6694.95, 6617.28, 6645.87, 6620.61, 6504.57, 6570.76, 6542.43, 6561.85, 6503.34, 6549.24,
6549.24, 6546.42, 6558.46, 6583.42, 6614.21, 6576.96, 6571.84, 6573.22, 6639.11, 6663.19, 6664.72, 6663.8,
6625.68, 6631.93, 6650.69, 6652.84, 6638.49, 6600.73, 6620.56, 6668.46, 6720.31, 6742.14, 6756.23, 6716.27,
6678.15, 6676.92, 6685.01, 6706.89, 6667.85, 6702.79, 6692.8, 6727.18, 6720.93, 6669.69, 6659.09, 6645.67, 6684.4,
6775.85, 6750.29, 6827.39, 6863.31, 6892.66, 6899.84, 6859.87, 6831.75, 6831.75, 6835.9, 6809.46, 6826.67, 6748.85,
6702.02, 6720.52, 6738.96, 6801.77, 6756.18, 6744.39, 6619.74, 6585.62, 6580.85, 6565.53, 6581.16,
6597.4, 6623.28, 6580.19, 6587.57, 6579.21, 6489.61, 6451.49, 6432.63, 6464.96, 6519.07, 6603.55, 6609.96, 6629.78,
6664.06, 6672.67, 6669.49, 6720.36, 6672.36, 6637.16)
```
Загрузим необходимые библиотеки:
```R
library(tseries)
library(forecast)
library(knitr)
```
### Исследование ряда
Проверим ряд на стационарность с помощью расширенного метода Дики-Фуллера.
```R
adf.test(vec)
```
Augmented Dickey-Fuller Test
data:  vec
Dickey-Fuller = -2.1716, Lag order = 4, p-value = 0.5055
alternative hypothesis: stationary
```R
plot(vec, type="l", col="red", main="Исходный ряд")
```
![png](output_9_0.png)
P-value > 0.05, альтернативная гипотеза отклоняется. Ряд не стационарен.
Зададим функцию дифференцирования ряда, продифференцируем исходный ряд и вновь проведем тест Дики-Фуллера.
```R
differentiation <- function(Y, n)
{
Y1 <- Y
first_elems <- vector()
for (i in 1:n)
{
Y2 <- vector()
first_elems <- append(first_elems, Y1[1])
for (j in 1:(length(Y1) - 1)) Y2 <- append(Y2, Y1[j+1] - Y1[j])
Y1 <- Y2
}
return(list(diff = Y2, recover = rev(first_elems)))
}
new_vec <- differentiation(vec, 1)$diff
adf.test(new_vec)
```
Warning message in adf.test(new_vec):
"p-value smaller than printed p-value"
Augmented Dickey-Fuller Test
data:  new_vec
Dickey-Fuller = -4.7689, Lag order = 4, p-value = 0.01
alternative hypothesis: stationary
Продифференцированный 1 раз ряд является стационарным, можем принять альтернативную гипотезу.
```R
plot(new_vec, type="l", col="blue", main="Первая производная ряда")
```
![png](output_13_0.png)
### Проведение экспериментов
#### Вручную
Проведем аналогичные рассмотренным ранее в Excel эксперименты: составим отдельно модели AR и MA для дифференцированного ряда. Сведем результаты в общую таблицу и сделаем выводы.
Вычисление BIC:
```R
myBIC <- function(sigma, epsilon, coeffs) return(log(sigma^2) + length(coeffs)*log(length(epsilon))/length(epsilon))
```
Подсчет модели $$ AR(p): p \in [1..20] $$
```R
AR <- function(data, maxp=20)
{
arres <- data.frame()
coeffs <- list()
for (i in 1:maxp)
{
result <- arma(data, order = c(i, 0), include.intercept = F)
SD <- sd(na.omit(result$residuals))
bic <- myBIC(SD, na.omit(result$residuals), result$coef)
arres <- rbind(arres, c(SD, bic))
coeffs[[length(coeffs)+1]] <- list(result$coef)
}
colnames(arres) <- c("sigma", "BIC")
rownames(arres) <- seq(1, maxp)
return(list(coeff = coeffs, res = arres))
}
```
```R
ar <- AR(new_vec)
ar$res
```
Warning message in optim(coef, err, gr = NULL, hessian = TRUE, ...):
"one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly"
<table class="dataframe">
<caption>A data.frame: 20 × 2</caption>
<thead>
<tr><th></th><th scope=col>sigma</th><th scope=col>BIC</th></tr>
<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
<tr><th scope=row>1</th><td>40.28798</td><td>7.437801</td></tr>
<tr><th scope=row>2</th><td>40.13837</td><td>7.476769</td></tr>
<tr><th scope=row>3</th><td>39.90421</td><td>7.512210</td></tr>
<tr><th scope=row>4</th><td>39.85089</td><td>7.557431</td></tr>
<tr><th scope=row>5</th><td>40.03578</td><td>7.615357</td></tr>
<tr><th scope=row>6</th><td>40.06247</td><td>7.666152</td></tr>
<tr><th scope=row>7</th><td>39.67769</td><td>7.697127</td></tr>
<tr><th scope=row>8</th><td>38.68431</td><td>7.697532</td></tr>
<tr><th scope=row>9</th><td>38.49421</td><td>7.739655</td></tr>
<tr><th scope=row>10</th><td>38.42735</td><td>7.789038</td></tr>
<tr><th scope=row>11</th><td>37.82019</td><td>7.810955</td></tr>
<tr><th scope=row>12</th><td>37.64450</td><td>7.856349</td></tr>
<tr><th scope=row>13</th><td>37.20453</td><td>7.888505</td></tr>
<tr><th scope=row>14</th><td>35.82370</td><td>7.869523</td></tr>
<tr><th scope=row>15</th><td>35.57196</td><td>7.913099</td></tr>
<tr><th scope=row>16</th><td>35.17156</td><td>7.949191</td></tr>
<tr><th scope=row>17</th><td>33.33349</td><td>7.901655</td></tr>
<tr><th scope=row>18</th><td>32.55672</td><td>7.915429</td></tr>
<tr><th scope=row>19</th><td>32.72100</td><td>7.987576</td></tr>
<tr><th scope=row>20</th><td>32.75120</td><td>8.052689</td></tr>
</tbody>
</table>
(1) Можно заметить, что в сравнении с результатами, полученными в Excel, с увеличением количества коэффициентов увеличивается разница с полученными вручную значениями. Чаще значения дисперсии и байесовского информационного критерия оказываются немного ниже (в сотых долях) при расчете вручную (в Excel), нежели при расчете автоматической программой. В целом результаты оказываются практически одинаковыми с некоторой погрешностью.
```R
plot(seq(1, 20), ar$res$sigma, type="l", col ="red", main = "Среднеквадратичное отклонение", xlab = "AR(x)", ylab = "sigma")
plot(seq(1, 20), ar$res$BIC, type="l", col="blue", main = "BIC", xlab = "AR(x)", ylab = "bic")
```
![png](output_21_0.png)
![png](output_21_1.png)
Подсчет модели $$ MA(q): q \in [1..20] $$
```R
MA <- function(data, maxp=20)
{
arres <- data.frame()
coeffs <- list()
for (i in 1:maxp)
{
result <- arma(data, order = c(0, i), include.intercept = F)
SD <- sd(na.omit(result$residuals))
bic <- myBIC(SD, na.omit(result$residuals), result$coef)
arres <- rbind(arres, c(SD, bic))
coeffs[[length(coeffs)+1]] <- list(result$coef)
}
colnames(arres) <- c("sigma", "BIC")
rownames(arres) <- seq(1, maxp)
return(list(coeff = coeffs, res = arres))
}
```
```R
ma <- MA(new_vec)
ma$res
```
Warning message in optim(coef, err, gr = NULL, hessian = TRUE, ...):
"one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly"
Warning message in arma(data, order = c(0, i), include.intercept = F):
"Hessian negative-semidefinite"
Warning message in arma(data, order = c(0, i), include.intercept = F):
"Hessian negative-semidefinite"
Warning message in arma(data, order = c(0, i), include.intercept = F):
"Hessian negative-semidefinite"
Warning message in arma(data, order = c(0, i), include.intercept = F):
"Hessian negative-semidefinite"
Warning message in arma(data, order = c(0, i), include.intercept = F):
"Hessian negative-semidefinite"
<table class="dataframe">
<caption>A data.frame: 20 × 2</caption>
<thead>
<tr><th></th><th scope=col>sigma</th><th scope=col>BIC</th></tr>
<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
<tr><th scope=row>1</th><td>40.31433</td><td>7.439108</td></tr>
<tr><th scope=row>2</th><td>39.92585</td><td>7.466151</td></tr>
<tr><th scope=row>3</th><td>39.97579</td><td>7.515794</td></tr>
<tr><th scope=row>4</th><td>40.14113</td><td>7.571945</td></tr>
<tr><th scope=row>5</th><td>39.55950</td><td>7.591421</td></tr>
<tr><th scope=row>6</th><td>39.66896</td><td>7.646410</td></tr>
<tr><th scope=row>7</th><td>38.75870</td><td>7.650259</td></tr>
<tr><th scope=row>8</th><td>39.07772</td><td>7.717768</td></tr>
<tr><th scope=row>9</th><td>38.71804</td><td>7.751250</td></tr>
<tr><th scope=row>10</th><td>38.65932</td><td>7.801074</td></tr>
<tr><th scope=row>11</th><td>38.80498</td><td>7.862366</td></tr>
<tr><th scope=row>12</th><td>38.49167</td><td>7.900858</td></tr>
<tr><th scope=row>13</th><td>37.34415</td><td>7.895996</td></tr>
<tr><th scope=row>14</th><td>37.64063</td><td>7.968472</td></tr>
<tr><th scope=row>15</th><td>34.97837</td><td>7.879444</td></tr>
<tr><th scope=row>16</th><td>36.42945</td><td>8.019471</td></tr>
<tr><th scope=row>17</th><td>34.70892</td><td>7.982523</td></tr>
<tr><th scope=row>18</th><td>32.61740</td><td>7.919152</td></tr>
<tr><th scope=row>19</th><td>33.25573</td><td>8.019996</td></tr>
<tr><th scope=row>20</th><td>32.48148</td><td>8.036150</td></tr>
</tbody>
</table>
Аналогично (1) получили примерно те же результаты, что и при подсчете вручную. Немного хуже оказываются результаты, полученные автоматически.
```R
plot(seq(1, 20), ma$res$sigma, type="l", col ="red", main = "Среднеквадратичное отклонение", xlab = "AR(x)", ylab = "sigma")
plot(seq(1, 20), ma$res$BIC, type="l", col="blue", main = "BIC", xlab = "AR(x)", ylab = "bic")
```
![png](output_26_0.png)
![png](output_26_1.png)
Лучшими по байесовскому информационному критерию снова оказались модели MA(1) и AR(1).
Построение модели $$ARMA(p, q): q \in \{0, 1, 2\}, p \in \{0, 1, 2\} $$
```R
ARMA <- function(data)
{
arres <- data.frame()
coeffs <- list()
names <- vector()
for (i in 0:2)
{
for (j in 0:2)
{
if (i!=0 || j!=0)
{
result <- arma(data, order = c(i, j), include.intercept = F)
SD <- sd(na.omit(result$residuals))
bic <- myBIC(SD, na.omit(result$residuals), result$coef)
arres <- rbind(arres, c(SD, bic))
names <- append(names, paste("ARIMA(", i, ", 1, ",  j, ")", sep=""))
coeffs[[length(coeffs)+1]] <- list(result$coef)
}
}
}
colnames(arres) <- c("sigma", "BIC")
rownames(arres) <- names
return(list(coeff = coeffs, res = arres, name = names))
}
```
```R
myarma <- ARMA(new_vec)
myarma$res
```
Warning message in optim(coef, err, gr = NULL, hessian = TRUE, ...):
"one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly"
Warning message in optim(coef, err, gr = NULL, hessian = TRUE, ...):
"one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly"
<table class="dataframe">
<caption>A data.frame: 8 × 2</caption>
<thead>
<tr><th></th><th scope=col>sigma</th><th scope=col>BIC</th></tr>
<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
<tr><th scope=row>ARIMA(0, 1, 1)</th><td>40.31433</td><td>7.439108</td></tr>
<tr><th scope=row>ARIMA(0, 1, 2)</th><td>39.92585</td><td>7.466151</td></tr>
<tr><th scope=row>ARIMA(1, 1, 0)</th><td>40.28798</td><td>7.437801</td></tr>
<tr><th scope=row>ARIMA(1, 1, 1)</th><td>40.24054</td><td>7.481139</td></tr>
<tr><th scope=row>ARIMA(1, 1, 2)</th><td>39.82148</td><td>7.506968</td></tr>
<tr><th scope=row>ARIMA(2, 1, 0)</th><td>40.13837</td><td>7.476769</td></tr>
<tr><th scope=row>ARIMA(2, 1, 1)</th><td>39.99588</td><td>7.515708</td></tr>
<tr><th scope=row>ARIMA(2, 1, 2)</th><td>38.62280</td><td>7.491893</td></tr>
</tbody>
</table>
Заметим, что результаты получились такими же, что и при расчете вручную, за исключением модели ARIMA(2, 1, 2). Программа получила на единицу меньшее средневадратичное отклонение и на 6 сотых меньший байесовский информационный критерий.
```R
plot(seq(1:length(myarma$name)), myarma$res$sigma, type="l", col ="red", main = "Среднеквадратичное отклонение", xlab = "AR(x)", ylab = "sigma", xaxt = "n", las=2)
axis(1, at=1:length(myarma$name), labels=myarma$name, las = 2, cex.axis =0.75)
plot(seq(1:length(myarma$name)), myarma$res$BIC, type="l", col="blue", main = "BIC", xlab = "AR(x)", ylab = "bic", xaxt = "n")
axis(1, at=seq(1:length(myarma$name)), labels=myarma$name, las = 2, cex.axis =0.75)
```
![png](output_32_0.png)
![png](output_32_1.png)
$ARIMA(1, 1, 0)$ по-прежнему оказалась лучшей моделью согласно байесовскому информационному критерию.
Полученная модель имеет вид: $X_t = 0.08509 \bullet X_{t-1} + e_t$
Для получения исходного ряда необходимо проинтегрировать текущий один раз.
```R
bestarma <- arma(new_vec, order = c(1, 0), include.intercept = F)
bestarma$coef
```
Warning message in optim(coef, err, gr = NULL, hessian = TRUE, ...):
"one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly"
<strong>ar1:</strong> 0.0850892826280358
#### Автоматически
Запустим автоматический подбор параметров ARIMA.
```R
autoar <- auto.arima(vec, ic = "bic", trace=TRUE)
autoar
```
ARIMA(2,0,2) with non-zero mean : 1071.022
ARIMA(0,0,0) with non-zero mean : 1243.914
ARIMA(1,0,0) with non-zero mean : 1062.969
ARIMA(0,0,1) with non-zero mean : 1158.728
ARIMA(0,0,0) with zero mean     : 2110.8
ARIMA(2,0,0) with non-zero mean : 1065.836
ARIMA(1,0,1) with non-zero mean : 1066.363
ARIMA(2,0,1) with non-zero mean : 1069.125
ARIMA(1,0,0) with zero mean     : Inf
Best model: ARIMA(1,0,0) with non-zero mean
Series: vec
ARIMA(1,0,0) with non-zero mean
Coefficients:
ar1       mean
0.9088  6669.5490
s.e.  0.0380    38.6204
sigma^2 estimated as 1556:  log likelihood=-524.53
AIC=1055.06   AICc=1055.31   BIC=1062.97
Полученная модель имеет вид:
$$(1-0.9088B)(X_t-6669.5490)=e_t$$
$$X_t = (1-0.9088)*(6669.5490)+0.9088*X_{t-1}+e_t = 0.9088*X_{t-1} + 608.26286 + e_t$$
$$X_t = 0.9088*X_{t-1} + 608.26286 + e_t$$
```R
sd(autoar$residuals)
```
39.2454418224469
```R
myBIC(sd(autoar$residuals), na.omit(autoar$residuals), autoar$coef)
```
7.42966534878034
Заметим, что автоматический подбор коэффициентов модели показал лучший результат как по среднеквадратичному отклонению, так и по байесовскому информационному критерию.
При этом модель не сочла нужным дифференцировать исходный ряд. Действительно, в каком-то смысле можно назвать его близким к стационарному, поскольку осуществляются колебания около некоторого значения, близкого к среднему по ряду.
```R
plot(vec, type="l")
lines(seq(1, length(vec)), rep(mean(vec), length(vec)), col="red")
```
![png](output_42_0.png)
s1 <- c(56.7, 45.3, 89.6, 40.2, 45.2)
s2 <- c(76.7, 65.7, 90.3, 101.6, 116.2)
t.test(s1, s2)
setwd("C:/R/lab5")
path <- "C:\\R\\lab5\\nut_dataframe.csv"
df <- read.csv(path, fileEncoding = "UTF-8", stringsAsFactors = FALSE)
df <- na.omit(df[, -1])
require(ggplot2)
require(factoextra)
require(resample)
# с помощью встроенных функций
# вначале рассмотрим матрицу ковариации исходных переменных
print(cov(df), digits = 2) #тут книтр
# применяем метод главных компонент
df_pca <- prcomp(df, scale = T, center = T)
df_pca$x
df
length(colnames(df))
