---
title: "lab4"
author: "Tsvetkov Alex"
date: "31 10 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Подготовительные действия

```{r}
filepath <- "C:\\R\\lab4\\nut_dataframe.csv"

require(nortest)
require(ggplot2)
require(moonBook)
require(webr)
require(kableExtra)
require(dplyr)

nut_dataframe <- read.csv(filepath, fileEncoding = "UTF-8", stringsAsFactors = FALSE)
# удалим строки с NA

nut_dataframe <- nut_dataframe[rowSums(is.na(nut_dataframe)) <= 0,]

kable(nut_dataframe) %>%
  kable_styling("striped", full_width = F) %>%
  scroll_box(width = "100%", height = "400px")
```

## Задание №1

**Выбрать из DataFrame 2 количественные и 2 качественные переменные. **  

```{r}
#количественные
nopodsweight <- nut_dataframe$NoPodsWeight
height <- nut_dataframe$Height
```

**Проверить количественные переменные на нормальность.**  
Примем уровень значимости равным 0.05. Будем проверять гипотезу H_0: случайная величина распределена нормально. Проведем два теста - Лиллиефорса и Шапиро-Уилка.  

```{r}
# критерий Шапиро-Уилка
shapiro.test(nopodsweight)
shapiro.test(height)

# критерий Лиллиефорса
lillie.test(nopodsweight)
lillie.test(height)
```

По результатам тестов можем видеть, что для переменной `nopodsweight` гипотеза о нормальности не отвергается, а для `height` отвергается (все так же при уровне значимости 0.05). Построим гистограммы и убедимся в правильности наших рассуждений.  

```{r}
# nopodsweight
ggplot(nut_dataframe, aes(x = NoPodsWeight)) + 
  geom_histogram(color="black", fill="white", aes(y = ..density..)) + 
  geom_density(aes(color = "blue"), size = 2) +
  stat_function(fun = dnorm, args = list(mean = mean(nut_dataframe$NoPodsWeight), 
                                         sd = sd(nut_dataframe$NoPodsWeight)), 
                aes(color = "red"), size = 2, alpha = 0.7) +
  scale_color_identity(name = "Lines",
                       breaks = c("blue", "red"),
                       labels = c("Data density", "Normal distribution"),
                       guide = "legend") +
  ggtitle("NoPodsWeight distribution")
```

```{r}
ggplot(nut_dataframe, aes(x = Height)) + 
  geom_histogram(color="black", fill="white", aes(y = ..density..)) + 
  geom_density(aes(color = "blue"), size = 2) +
  stat_function(fun = dnorm, args = list(mean = mean(nut_dataframe$Height), 
                                         sd = sd(nut_dataframe$Height)), 
                aes(color = "red"), size = 2, alpha = 0.7) +
  scale_color_identity(name = "Lines",
                       breaks = c("blue", "red"),
                       labels = c("Data density", "Normal distribution"),
                       guide = "legend") +
  ggtitle("Height distribution")
```

Из графиков также видно, что распределение у `nopodsweight` похоже на нормальное, а у `height` оно слишком разрежено.  

**Разбить значения количественных переменных относительно значений качественных. **  

```{r}
# взятые качественные переменные - BushShape и FlowStemCol

# разобъем датафреймы по значениям BushShape и FlowStemCol

nut2_bushshape <- group_split(nut_dataframe %>% group_by(BushShape))
nut2_flowstemcol <- group_split(nut_dataframe %>% group_by(FlowStemCol))
```

**Проверить полученные подвыборки на нормальность. **  

```{r encoding="UTF-8"}
check_normality <- function(tibble, mode = "shapiro")
{
  for(i in 1:length(tibble))
  {
    bushshape_in_tibble <- tibble[[i]]$BushShape
    flowstemcol_in_tibble <- tibble[[i]]$FlowStemCol
    npw_in_tibble <- tibble[[i]]$NoPodsWeight
    height_in_tibble <- tibble[[i]]$Height
    print("Sorted by: ")
    if (all(bushshape_in_tibble == bushshape_in_tibble[1]))
    {
        print(paste("Bushshape: ", bushshape_in_tibble[1]))
    }
    if (all(flowstemcol_in_tibble == flowstemcol_in_tibble[1])) 
    {
        print(paste("FlowStemCol: ", flowstemcol_in_tibble[1]))
    }
    switch(mode, 
           "shapiro" = {
             print(shapiro.test(npw_in_tibble))
             print(shapiro.test(height_in_tibble))
           },
           "lillie" = {
             print(lillie.test(npw_in_tibble))
             print(lillie.test(height_in_tibble))
           },
     )
  }
}

check_normality(nut2_bushshape, "shapiro")
check_normality(nut2_flowstemcol, "lillie")
```
По результатам тестов можем видеть, что для переменной `NoPodsWeight` разделение по `FlowStemCol` остается нормальным (гипотеза не отвергается) в обоих подвыборках. Для переменной `NoPodsWeight` разделение по `BushShape` дает одну нормально распределенную подвыборку; для второй гипотеза о нормальности отвергается. Для остальных выборок, разбитых попарно по выбранным количественным/качественным переменным, гипотеза о нормальности также отвергается.  

**Реализовать для подвыборок t-test помощью встроенной функции.**  
Сначала проведем тест Фишера, чтобы проверить равенство дисперсий: гипотеза H0 - дисперсии двух распределений равны.   

```{r}
# разделение height + bushshape

var.test(nut2_bushshape[[1]]$Height, nut2_bushshape[[2]]$Height)

# разделение nopodsweight + flowstemcol

var.test(nut2_flowstemcol[[1]]$NoPodsWeight, nut2_flowstemcol[[2]]$NoPodsWeight)
```
По результатам теста можем видеть, что для разделения количественной переменной `Height` по качественной `BushShape` гипотеза о равенстве дисперсий не подтверждается. Для разделения `NoPodsWeight` по `FlowStemCol` гипотеза о равенстве дисперсий не отвергается.  
Используя полученные данные, запустим `t.test` с параметром о равенстве/неравенстве дисперсий.  
Наша гипотеза для теста Стьюдента: математические ожидания выборок равны.

```{r}
# разделение height + bushshape

t.test(nut2_bushshape[[1]]$Height, nut2_bushshape[[2]]$Height, var.equal = F)

# разделение nopodsweight + flowstemcol

t.test(nut2_flowstemcol[[1]]$NoPodsWeight, nut2_flowstemcol[[2]]$NoPodsWeight, var.equal = T)
```
После проведения теста Стьюдента можно заметить следующие результаты: для первого разделения (`Height` + `BushShape`) гипотеза о равенстве математических ожиданий может быть не отвергнута. Для второго же разделения (`NoPodsWeight` + `FlowStemCol`) гипотеза о равенстве математических ожиданий уверенно отвергается.  

**...и вручную (реализовав формулу):**

```{r}
mytest_student <- function(sample1, sample2) return((mean(sample1)-mean(sample2))/sqrt(var(sample1)/length(sample1) + var(sample2)/length(sample2)))

# разделение height + bushshape

mytest_student(nut2_bushshape[[1]]$Height, nut2_bushshape[[2]]$Height)

# разделение nopodsweight + flowstemcol

mytest_student(nut2_flowstemcol[[1]]$NoPodsWeight, nut2_flowstemcol[[2]]$NoPodsWeight)
```
Видим, что значения статистики, посчитанные вручную, получились такими же, как и посчитанные с помощью встроенного пакета. Значит, выводы, приведенные выше, верны.  

**Вывести графики с распределениями переменных и статистики t-test.**

Подтвердим наши выводы, нарисовав графики распределений с использованием полученных данных из тестов.

```{r}
ggplot(nut2_bushshape[[1]], aes(x = Height)) + 
  geom_histogram(aes(y = ..density..), color="darkgreen", fill = "darkgreen", alpha = 0.7) +
  geom_histogram(data = nut2_bushshape[[2]], aes(x=Height, y = ..density..), color="orange", fill = "orange", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = mean(nut2_bushshape[[1]]$Height), 
                                         sd = sd(nut2_bushshape[[1]]$Height)), aes(color = "Normal distribution 1"), size = 1.5) +
  stat_function(fun = dnorm, args = list(mean = mean(nut2_bushshape[[2]]$Height), 
                                         sd = sd(nut2_bushshape[[2]]$Height)), aes(color = "Normal distribution 2"), size = 1.5) +
  stat_function(fun = dt, args = list(df = 387.96), aes(color = "t.test distribution"), size = 1.5) +
  ggtitle("Height for bushshape")

```

Действительно, в данном случае параметры сдвига могут иметь близкие значения. Также по гистограммам видим, что переменные не имеют нормального распределения.

```{r}
ggplot(nut2_flowstemcol[[1]], aes(x = NoPodsWeight)) + 
  geom_histogram(aes(y = ..density..), color="darkred", fill = "darkred", alpha = 0.7) +
  geom_histogram(data = nut2_flowstemcol[[2]], aes(x=NoPodsWeight, y = ..density..), color="blue", fill = "blue", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = mean(nut2_flowstemcol[[1]]$NoPodsWeight), 
                                         sd = sd(nut2_flowstemcol[[1]]$NoPodsWeight)), aes(color = "Normal distribution 1"), size = 1.5) +
  stat_function(fun = dnorm, args = list(mean = mean(nut2_flowstemcol[[2]]$NoPodsWeight), 
                                         sd = sd(nut2_flowstemcol[[2]]$NoPodsWeight)), aes(color = "Normal distribution 2"), size = 1.5) +
  stat_function(fun = dt, args = list(df = 402), aes(color = "t.test distribution"), size = 1.5) +
  ggtitle("NoPodsWeight for flowstemcol")

```

Этот график также подтверждает выводы из тестов - параметры сдвига у переменных явно разные, однако параметры масштаба практически одинаковы. Также видим, что гипотеза равномерном распределении подвыброк не отвергается.

## Задание №2

**Выбрать 2 качественные переменные из старого DataFrame, проанализировать зависимость между ними с помощью критерия Хи-квадрат с помощью встроенной функции. **

Здесь гипотеза H0 звучит так: выборка №1 не зависит от выборки №2.

```{r}
bushape <- nut_dataframe$BushShape
flowstemcol <- nut_dataframe$FlowStemCol

# с помощью встроенной функции

# без поправки Йетса
chisq_test <- chisq.test(table(bushape, flowstemcol), correct = F)
chisq_test
# c поправкой Йетса
chisq.test(table(bushape, flowstemcol))
```
Из полученных результатов можно сделать вывод, что гипотеза H0 отвергается: значение статистики значительно превышает допустимое при выбранном уровне значимости 0.05 и 1 степенью свободы: 14.058 > 13.315 > 3.84.

**...и вручную: **

```{r}
my_chi_squared <- function(sample1, sample2)
{
  myframe <- data.frame(sample1 = sample1, sample2 = sample2)
  
  dataformatrix <- group_split(myframe %>% group_by(sample1, sample2))
  
  chi <- vector()
  observed <- data.frame()
  expected <- data.frame()
  
  numofdata <- length(sample1)
  
  for (i in 1:length(dataformatrix))
  {
    # таблица сопряженности
    workmatrix <- dataformatrix[[i]]
    name1 <- workmatrix$sample1[1]
    name2 <- workmatrix$sample2[1]
    
    observed[toString(name1), toString(name2)] <- length(workmatrix$sample1)
  }
  
  # проверяем гипотезу H_0, что x не зависит от y
  for (i in 1:nrow(observed))
  {
    summa <- sum(observed[i, ])
    for (j in 1:ncol(observed))
    {
      expected[i, j] <- summa * sum(observed[, j]) / numofdata
    }
  }
  
  for (i in 1:nrow(observed))
  {
    for(j in 1:nrow(observed)) 
    {
      chi <- append(chi, (observed[i, j] - expected[i, j])^2/expected[i, j])
    }
  }
  return(sum(chi))
}

my_chi_squared(bushape, flowstemcol)

```

**Сравнить результат с тем, который получился при использовании встроенной функции в R.**  
Так, получаем, что значения, посчитанные вручную и с помощью встроенной функции, получились одинаковыми (без поправки Йетса). Гипотеза отвергается.

**Построить для теста распределение статистики. На графике обозначить области принятия и отклонения гипотезы, уровень отсечения и значение статистики, полученное для статистического теста.**

Проверим сделанные выводы, нарисовав график статистики.

```{r}

plot(chisq_test) + stat_function(fun = dchisq, args = list(df = 1), size = 1.3) + xlim(0, 15) + 
  geom_hline(yintercept = 0) +
  geom_point(aes(x=chisq_test$statistic, y=dchisq(chisq_test$statistic, df = 1)), colour="blue", size = 4) +
  geom_vline(xintercept = qchisq(.95, df = 1), color = "red", linetype = "dashed") +
  geom_text(aes(x=1, y = 0.1), label = "95%")
```

Действительно, полученное значение статистики сильно выбивается от допустимых значений для распределения с такими параметрами.

